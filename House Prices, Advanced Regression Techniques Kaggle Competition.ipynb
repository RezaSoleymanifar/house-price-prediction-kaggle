{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Prices, Advanced Regression Techniques Kaggle Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset: Ames Housing dataset (50 features)\n",
    "technologies:\n",
    "algorithms:\n",
    "results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the dataset here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "root = 'datasets/kaggle-boston'\n",
    "def load_housing_data(root=root):\n",
    "    csv_path_train = os.path.join(root, 'train.csv')\n",
    "    csv_path_test = os.path.join(root, 'test.csv')\n",
    "    data_train, data_test = pd.read_csv(csv_path_train), pd.read_csv(csv_path_test)\n",
    "    return data_train, data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = load_housing_data()\n",
    "y_train = data_train['SalePrice'].copy()\n",
    "data_train.drop('SalePrice', axis = 1, inplace = True)\n",
    "# full_pipeline = joblib.load(\"full_pipeline.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def display_stats(col_name):\n",
    "#     divider = '\\n---------'\n",
    "#     col = data_train[col_name]\n",
    "#     print(\"\"\" \n",
    "#     **********************\n",
    "#     column name: {0}\n",
    "#     ----------------------\n",
    "#     value counts:\\n {1}\n",
    "#     ----------------------\n",
    "#     null values:\\n {2}\n",
    "#     \"\"\".format(col_name, col.value_counts(), col.isna().sum()))\n",
    "\n",
    "# def show_all_stats(data):\n",
    "#     for col in data.columns:\n",
    "#         display_stats(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# show_all_stats(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------\n",
    "# #**DROP COL**: Street (6 outliers), Alley (1369 nulls), Utilities (1 outlier), Condition2 (15 outliers),\n",
    "# #RoofMatl (26 outliers), Heating (32 outliers), PoolArea (7 outliers),PoolQC (1453 nulls), \n",
    "# #MiscFeature (1406 nulls), \n",
    "# --------------------------------------------------\n",
    "# #DROP ROW: MasVnrType, Electrical, GarageYrBlt, GarageFinish,  GarageQual, GarageCond\n",
    "# --------------------------------------------------\n",
    "# #**FILLNA**: GarageType, GarageFinish, BsmtQual, BsmtExposure, BsmtCond, BsmtFinType1, BsmtFinType2,\n",
    "# #Fence, FireplaceQu, GarageType, \n",
    "# --------------------------------------------------\n",
    "# #**ORDINAL ENCODING**: ExterQual (qual_dict), ExterCond (qual_dict), BsmtQual (qual_dict),\n",
    "# #BsmtCond (qaul_dict), BsmtExposure (exposure_dict),\n",
    "# #BsmtFinType1 (basement_finish_dict), BsmtFinType2 (basement_finish_dict), HeatingQC (qual_dict),\n",
    "# #CentralAir (0 or 1), KitchenQual, Functional (functional_dict), GarageQual (qual_dict),\n",
    "# #GarageCond (qual_dict), Fence(fence_dict), FireplaceQu (qaul_dict)\n",
    "# --------------------------------------------------\n",
    "# #**ALTER**: YearBuilt (to age), YearRemodAdd (to age), GarageYrBlt (to age), YrSold (to age)\n",
    "# --------------------------------------------------\n",
    "# #**MERGE COLS**: OverallQual, OverallCond (average)/Exterior1st, Exterior2nd/ExterQual, ExterCond (average)\n",
    "# #BsmtCond, BsmtCond (avg. after encoding)/ GarageQual and GarageCond (avg. after encoding)\n",
    "# #OpenPorchSF, EnclosedPorch, 3SsnPorch, ScreenPorch (sum)/\n",
    "# --------------------------------------------------\n",
    "# #**IMPUTE**: LotFrontage (median 69), MasVnrArea (median 0), \n",
    "# --------------------------------------------------\n",
    "# #**ONEHOT**: MSSubClass, MSZoning, LotShape, LandContour, LotConfig, LandSlope, Neighborhood, Condition1, BldgType\n",
    "# #HouseStyle, RoofStyle, *[Exterior1st, Exterior2nd], MasVnrType, Foundation, Electrical,\n",
    "# #GarageType, GarageFinish, PavedDrive, MoSold, SaleType, SaleCondition\n",
    "# --------------------------------------------------\n",
    "# #**LABELS**: SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cat datasets/kaggle-boston/data_description.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 60)\n",
    "pd.set_option('display.max_rows', 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# corr_matrix= data_train.corr()\n",
    "# corr_matrix[\"SalePrice\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "# data_train.hist(bins=100, figsize=(20,15))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might want to consider dropping the values that have the least correlation (abs value) with sales prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_drop_cols = ['Street', 'Alley', 'Utilities', 'Condition2',\n",
    "                  'RoofMatl', 'Heating', 'PoolArea','PoolQC','MiscFeature', 'Id']\n",
    "list_fill_na =  ['GarageType', 'GarageFinish', 'BsmtQual', 'BsmtCond',\n",
    "                 'BsmtFinType1', 'BsmtFinType2', 'Fence', 'FireplaceQu', 'GarageType', 'BsmtExposure',\n",
    "                'MasVnrType', 'Electrical', 'GarageYrBlt', 'GarageFinish',  'GarageQual', 'GarageCond']\n",
    "# list_drop_rows = ['MasVnrType', 'Electrical', 'GarageYrBlt', 'GarageFinish',  'GarageQual', 'GarageCond']\n",
    "list_ordinal_columns = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond',\n",
    "                        'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', \n",
    "                        'HeatingQC', 'CentralAir', 'KitchenQual', 'Functional', \n",
    "                        'GarageQual', 'GarageCond', 'Fence', 'FireplaceQu']\n",
    "list_change_year = ['YearBuilt', 'YearRemodAdd', 'GarageYrBlt','YrSold']\n",
    "\n",
    "list_cat_cols = ['MSSubClass', 'MSZoning', 'LotShape', 'LandContour',\n",
    "                'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'BldgType',\n",
    "                'HouseStyle', 'RoofStyle', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'Foundation', 'Electrical',\n",
    "                'GarageType', 'GarageFinish', 'PavedDrive', 'MoSold',\n",
    "                 'SaleType', 'SaleCondition', 'CentralAir']\n",
    "list_num_cols = set(data_train.columns) - set(list_cat_cols)\n",
    "list_cat_cols, list_num_cols = list(list_cat_cols), list(list_num_cols)\n",
    "cols = data_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_most_common_imputed = colors.apply(lambda x: x.fillna(x.value_counts().index[0]))\n",
    "#df['X1'] = df['X1'].fillna(df['X1'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we cast some categorical values into ordinal codes. This avoids transforming into one hot vectors which take more space and destroy the ordinal relationship between these categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "qual_dict = {'Ex':5 ,'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 0:0}\n",
    "qual_dict_cols = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond',\n",
    "                  'HeatingQC', 'GarageCond', 'FireplaceQu', 'GarageQual',\n",
    "                 'KitchenQual']\n",
    "\n",
    "exposure_dict = {'Gd':4, 'Av':3, 'Mn':2, 'No':1, 0:0}\n",
    "exposure_dict_cols = ['BsmtExposure']\n",
    "\n",
    "basement_finish_dict = {'GLQ':6, 'ALQ':5, 'BLQ':4, 'Rec':3, 'LwQ':2, 'Unf':1, 0:0}\n",
    "basement_finish_dict_cols = ['BsmtFinType1', 'BsmtFinType2']\n",
    "\n",
    "functional_dict = {'Typ':7, 'Min1':6, 'Min2':5, 'Mod':4, 'Maj1':3, 'Maj2':2, 'Sev':1, 'Sal':0}\n",
    "functional_dict_cols = ['Functional']\n",
    "\n",
    "fence_dict = {'GdPrv':4, 'MnPrv':3, 'GdWo':2, 'MnWw':1, 0:0 }\n",
    "fence_dict_cols= ['Fence']\n",
    "\n",
    "\n",
    "ordinal_mapping_list = [[qual_dict_cols, qual_dict], [exposure_dict_cols, exposure_dict],\n",
    "                 [basement_finish_dict_cols, basement_finish_dict], [functional_dict_cols, functional_dict],\n",
    "                  [fence_dict_cols, fence_dict]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the preprocessing pipeline:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pdpipe as pdp\n",
    "import math\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def fillna_0(x):\n",
    "    return 0 if pd.isnull(x) else x\n",
    "def is_null(x):\n",
    "    return pd.isnull(x)\n",
    "def to_age(x):\n",
    "    return 2020 - x\n",
    "\n",
    "#drop unwanted columns here\n",
    "pipeline = pdp.ColDrop(list_drop_cols)\n",
    "#fill nan values\n",
    "pipeline += pdp.ApplyByCols(columns = list_fill_na, func = fillna_0)\n",
    "#apply ordinal condings here\n",
    "\n",
    "for coldict in ordinal_mapping_list:\n",
    "    pipeline += pdp.MapColVals(coldict[0], coldict[1])\n",
    "#apply one hot encoding here\n",
    "pipeline += pdp.OneHotEncode(list_cat_cols)\n",
    "#transform dates to ages:\n",
    "pipeline += pdp.ApplyByCols(list_change_year, to_age)\n",
    "# impute missing numeric values and standardization\n",
    "pipeline = Pipeline([\n",
    "           (\"pipe\", pipeline),\n",
    "           (\"impute\", SimpleImputer(strategy = 'median')),\n",
    "           ('std_scaler', StandardScaler())\n",
    "            ])\n",
    "# ('pca', PCA(n_components = 160))\n",
    "pipeline_input = pipeline\n",
    "\n",
    "X_train = pipeline.fit_transform(data_train)\n",
    "\n",
    "# X_test = pipeline_input.fit_transform(data_test)\n",
    "# y_test = pipeline_label.transform(data_test)['SalePrice'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 204) (1460,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok! now we're ready to experiment with some algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "forest_reg = RandomForestRegressor(n_estimators=100, max_features = 50, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.12933458 0.15511518 0.14568898 0.13949021 0.14198261]\n",
      "Mean: 0.14232231180377367\n",
      "Standard deviation: 0.008388197500691736\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(forest_reg, X_train, y_train,\n",
    "                         scoring=\"neg_mean_squared_log_error\", cv=5)\n",
    "forest_rmse_scores = np.sqrt(-scores)\n",
    "display_scores(forest_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'max_features':[40, 50, 60]}]\n",
    "\n",
    "# 'bootstrap':[True, False], 'ccp_alpha':[0.0, 0.5],\n",
    "\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_log_error', return_train_score=True, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n",
       "                                             criterion='mse', max_depth=None,\n",
       "                                             max_features='auto',\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             max_samples=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             n_estimators=100, n_jobs=None,\n",
       "                                             oob_score=False, random_state=42,\n",
       "                                             verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid=[{'max_features': [40, 50, 60]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='neg_mean_squared_log_error', verbose=0)"
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def display_res(cvres):\n",
    "    for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "        print(np.sqrt(-mean_score), params)\n",
    "    print('best:', np.sqrt(-cvres['mean_test_score']).min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13871729628882248 {'n_estimators': 100}\n",
      "0.13894420609670532 {'n_estimators': 200}\n",
      "0.1391087282879602 {'n_estimators': 300}\n",
      "0.13892702328258136 {'n_estimators': 400}\n",
      "best: 0.13871729628882248\n"
     ]
    }
   ],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "display_res(cvres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# result = pd.DataFrame({'real': y_train, 'random_forest': best_forest_reg.predict(X_train)})\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# y_pred = forest_reg.predict(R_test)\n",
    "# forest_mse = mean_squared_error(u_test, y_pred)\n",
    "# forest_rmse = np.sqrt(forest_mse)\n",
    "# forest_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train a multilayer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "mlp_reg = MLPRegressor(hidden_layer_sizes= (200,), alpha= 0.01,\n",
    "                       solver = 'lbfgs', max_iter = 200, early_stopping = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.15846955 0.1584831  0.19400091 0.19190455 0.18546726 0.16226672\n",
      " 0.14989675 0.17085231 0.21226427 0.17508782]\n",
      "Mean: 0.17586932312079057\n",
      "Standard deviation: 0.018689609304780044\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(mlp_reg, X_train, y_train,\n",
    "                         scoring=\"neg_mean_squared_log_error\", cv=10)\n",
    "mlp_rmse_scores = np.sqrt(-scores)\n",
    "display_scores(mlp_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'hidden_layer_sizes':[(200,),(100, 100), (100,)]}]\n",
    "\n",
    "grid_search = GridSearchCV(mlp_reg, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_log_error', return_train_score=True, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=MLPRegressor(activation='relu', alpha=0.01,\n",
       "                                    batch_size='auto', beta_1=0.9, beta_2=0.999,\n",
       "                                    early_stopping=True, epsilon=1e-08,\n",
       "                                    hidden_layer_sizes=(200,),\n",
       "                                    learning_rate='constant',\n",
       "                                    learning_rate_init=0.001, max_fun=15000,\n",
       "                                    max_iter=200, momentum=0.9,\n",
       "                                    n_iter_no_change=10,\n",
       "                                    nesterovs_momentum=True, power_t=0.5,\n",
       "                                    random_state=None, shuffle=True,\n",
       "                                    solver='lbfgs', tol=0.0001,\n",
       "                                    validation_fraction=0.1, verbose=False,\n",
       "                                    warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid=[{'hidden_layer_sizes': [(200,), (100, 100), (100,)]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='neg_mean_squared_log_error', verbose=0)"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_layer_sizes': (200,)}"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16951708136421015 {'hidden_layer_sizes': (200,)}\n",
      "0.17366974787218384 {'hidden_layer_sizes': (100, 100)}\n",
      "0.17493506472280582 {'hidden_layer_sizes': (100,)}\n",
      "best: 0.16951708136421015\n"
     ]
    }
   ],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "display_res(cvres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# y_pred = mlp_reg.predict(R_test)\n",
    "# mlp_mse = mean_squared_error(u_test, y_pred)\n",
    "# mlp_rmse = np.sqrt(mlp_mse)\n",
    "# mlp_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = pd.DataFrame({'real': u_test, 'prediction': mlp_reg.predict(R_test)})\n",
    "# result[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Tree Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    " from sklearn.ensemble import GradientBoostingRegressor\n",
    "    \n",
    "grad_boost_reg = GradientBoostingRegressor(loss = 'ls', subsample = 0.8,\n",
    "                                           max_features = 100,\n",
    "                                           random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.11822718 0.15227237 0.1392601  0.12234294 0.13353089]\n",
      "Mean: 0.1331266962751974\n",
      "Standard deviation: 0.01218707400366172\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(grad_boost_reg, X_train, y_train,\n",
    "                         scoring=\"neg_mean_squared_log_error\", cv=5)\n",
    "grad_rmse_scores = np.sqrt(-scores)\n",
    "display_scores(grad_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'max_features': [50, 100, 150]}]\n",
    "\n",
    "grid_search = GridSearchCV(grad_boost_reg, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_log_error', return_train_score=True, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,\n",
       "                                                 criterion='friedman_mse',\n",
       "                                                 init=None, learning_rate=0.1,\n",
       "                                                 loss='ls', max_depth=3,\n",
       "                                                 max_features=None,\n",
       "                                                 max_leaf_nodes=None,\n",
       "                                                 min_impurity_decrease=0.0,\n",
       "                                                 min_impurity_split=None,\n",
       "                                                 min_samples_leaf=1,\n",
       "                                                 min_samples_split=2,\n",
       "                                                 min_weight_fraction_leaf=0.0,\n",
       "                                                 n_estimators=100,\n",
       "                                                 n_iter_no_change=None,\n",
       "                                                 presort='deprecated',\n",
       "                                                 random_state=42, subsample=0.8,\n",
       "                                                 tol=0.0001,\n",
       "                                                 validation_fraction=0.1,\n",
       "                                                 verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid=[{'max_features': [50, 100, 150]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='neg_mean_squared_log_error', verbose=0)"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 100}"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12671053966499174 {'max_features': 50}\n",
      "0.12373608020689622 {'max_features': 100}\n",
      "0.12521558727516852 {'max_features': 150}\n",
      "best: 0.12373608020689622\n"
     ]
    }
   ],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "display_res(cvres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# y_pred = grad_boost_reg.predict(R_test)\n",
    "# grad_mse = mean_squared_error(u_test, y_pred)\n",
    "# grad_rmse = np.sqrt(grad_mse)\n",
    "# grad_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# result = pd.DataFrame({'real': u_test,\n",
    "#                        'grad_boost': grad_boost_reg.predict(R_test),\n",
    "#                        'forest_reg': forest_reg.predict(R_test)})\n",
    "# result[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "    \n",
    "extra_trees_reg = ExtraTreesRegressor(random_state = 42, bootstrap = False,\n",
    "                                     max_features = 80, n_estimators = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.13391116 0.11132908 0.13415728 0.16260474 0.15068944 0.10866148\n",
      " 0.13243258 0.11963481 0.13131705 0.13296382]\n",
      "Mean: 0.13177014360723918\n",
      "Standard deviation: 0.015556918920143013\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(extra_trees_reg, X_train, y_train,\n",
    "                         scoring=\"neg_mean_squared_log_error\", cv=10)\n",
    "extra_rmse_scores = np.sqrt(-scores)\n",
    "display_scores(extra_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'n_estimators':[80, 100, 120]}]\n",
    "\n",
    "grid_search = GridSearchCV(extra_trees_reg, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_log_error', return_train_score=True, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0,\n",
       "                                           criterion='mse', max_depth=None,\n",
       "                                           max_features=80, max_leaf_nodes=None,\n",
       "                                           max_samples=None,\n",
       "                                           min_impurity_decrease=0.0,\n",
       "                                           min_impurity_split=None,\n",
       "                                           min_samples_leaf=1,\n",
       "                                           min_samples_split=2,\n",
       "                                           min_weight_fraction_leaf=0.0,\n",
       "                                           n_estimators=100, n_jobs=None,\n",
       "                                           oob_score=False, random_state=42,\n",
       "                                           verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid=[{'n_estimators': [80, 100, 120]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='neg_mean_squared_log_error', verbose=0)"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 100}"
      ]
     },
     "execution_count": 564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.132929076094859 {'n_estimators': 80}\n",
      "0.13264600132415105 {'n_estimators': 100}\n",
      "0.13286305909155904 {'n_estimators': 120}\n",
      "best: 0.13264600132415105\n"
     ]
    }
   ],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "display_res(cvres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# y_pred = extra_trees_reg.predict(R_test)\n",
    "# extra_mse = mean_squared_error(u_test, y_pred)\n",
    "# extra_rmse = np.sqrt(extra_mse)\n",
    "# extra_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# result = pd.DataFrame({'real': u_test, 'extra_trees': extra_trees_reg.predict(R_test)})\n",
    "# result[50:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "    \n",
    "ada_reg = AdaBoostRegressor(n_estimators=200, random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.1748179  0.20418585 0.19170827 0.21275291 0.18407198]\n",
      "Mean: 0.19350738230379927\n",
      "Standard deviation: 0.0136086779561317\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(ada_reg, X_train, y_train,\n",
    "                         scoring=\"neg_mean_squared_log_error\", cv=5)\n",
    "ada_rmse_scores = np.sqrt(-scores)\n",
    "display_scores(ada_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'n_estimators':[100, 150, 200]}]\n",
    "\n",
    "grid_search = GridSearchCV(ada_reg, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_log_error', return_train_score=True, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=AdaBoostRegressor(base_estimator=None, learning_rate=1.0,\n",
       "                                         loss='linear', n_estimators=200,\n",
       "                                         random_state=42),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid=[{'n_estimators': [100, 150, 200]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='neg_mean_squared_log_error', verbose=0)"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 100}"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19025618402285144 {'n_estimators': 100}\n",
      "0.19308854777923257 {'n_estimators': 150}\n",
      "0.1939853167685184 {'n_estimators': 200}\n",
      "best: 0.19025618402285144\n"
     ]
    }
   ],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "display_res(cvres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# y_pred = ada_reg.predict(R_test)\n",
    "# ada_mse = mean_squared_error(u_test, y_pred)\n",
    "# ada_rmse = np.sqrt(ada_mse)\n",
    "# ada_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# result = pd.DataFrame({'real': y_train, 'prediction': ada_reg.predict(X_train)})\n",
    "# result[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "    \n",
    "svr_reg = SVR(kernel= 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [ 54943.25331179 114943.19975474  77511.18790708  76380.52651506\n",
      "  68725.43663352  84633.66923918  58670.11834652  71458.04096457\n",
      "  82511.72614474  94053.79597271]\n",
      "Mean: 78383.09547899135\n",
      "Standard deviation: 16499.552327392386\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(svr_reg, R_train, u_train,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
    "svr_rmse_scores = np.sqrt(-scores)\n",
    "display_scores(svr_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'kernel':['rbf', 'poly', 'sigmoid']}]\n",
    "\n",
    "grid_search = GridSearchCV(svr_reg, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_log_error', return_train_score=True, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3,\n",
       "                           epsilon=0.1, gamma='scale', kernel='sigmoid',\n",
       "                           max_iter=-1, shrinking=True, tol=0.001,\n",
       "                           verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid=[{'kernel': ['rbf', 'poly', 'sigmoid']}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='neg_mean_squared_log_error', verbose=0)"
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernel': 'sigmoid'}"
      ]
     },
     "execution_count": 618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3812299337123648 {'kernel': 'rbf'}\n",
      "0.38133478003688936 {'kernel': 'poly'}\n",
      "0.38102674129592085 {'kernel': 'sigmoid'}\n",
      "best: 0.38102674129592085\n"
     ]
    }
   ],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "display_res(cvres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# result = pd.DataFrame({'real': y_train, 'prediction': svr_reg.predict(X_train)})\n",
    "# result[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# y_pred = svr_reg.predict(R_test)\n",
    "# svr_mse = mean_squared_error(u_test, y_pred)\n",
    "# svr_rmse = np.sqrt(svr_mse)\n",
    "# svr_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [5.91890705e+04 2.25276214e+11 7.88765526e+09 4.26588924e+04\n",
      " 2.75359042e+04 3.18688036e+04 2.31796228e+11 2.23616073e+15\n",
      " 3.25762178e+17 3.32887628e+04]\n",
      "Mean: 3.279988041827724e+16\n",
      "Standard deviation: 9.765637500781464e+16\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(lin_reg, X_train, y_train,\n",
    "                         scoring=\"neg_mean_squared_log_error\", cv=10)\n",
    "lin_rmse_scores = np.sqrt(-scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27840.804388483954"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# y_pred = lin_reg.predict(X_train)\n",
    "# lin_mse = mean_squared_error(y_train, y_pred)\n",
    "# lin_rmse = np.sqrt(lin_mse)\n",
    "# lin_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# result = pd.DataFrame({'real': u_test,\n",
    "#                        'extra': extra_trees_reg.predict(R_test),\n",
    "#                        'linear': lin_reg.predict(R_test),\n",
    "#                        })\n",
    "# result[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking\n",
    "\n",
    "Let's stack some promising regressors together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "estimators = [\n",
    "    ('forest', forest_reg),\n",
    "    ('extra', extra_trees_reg),\n",
    "    ('grad_boost', grad_boost_reg),\n",
    "    ('mlp', mlp_reg),\n",
    "]\n",
    "\n",
    "#('forest', forest_reg),\n",
    "#('extra', extra_trees_reg),\n",
    "#('grad_boost', grad_boost_reg),\n",
    "#('mlp', mlp_reg)\n",
    "final_estimator = lin_reg\n",
    "#RandomForestRegressor(n_estimators=50)\n",
    "#AdaBoostRegressor(n_estimators=50, random_state=42)\n",
    "\n",
    "\n",
    "stack_reg = StackingRegressor(\n",
    "    estimators = estimators,\n",
    "    final_estimator = final_estimator)\n",
    "# RandomForestRegressor(n_estimators=10, random_state=42)\n",
    "\n",
    "pipeline_full = Pipeline([\n",
    "                ('input', pipeline_input),\n",
    "                ('reg', stack_reg)\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('input',\n",
       "                 Pipeline(memory=None,\n",
       "                          steps=[('pipe',\n",
       "                                  A pdpipe pipeline:\n",
       "[ 0]  Drop columns Street, Alley, Utilities, Condition2, RoofMatl, Heating,\n",
       "      PoolArea, PoolQC, MiscFeature, Id\n",
       "[ 1]  Applying a function  to columns GarageType, GarageFinish, BsmtQual,\n",
       "      BsmtCond, BsmtFinType1, BsmtFinType2, Fence, FireplaceQu, GarageType,\n",
       "      BsmtExposure, MasVnrType, Electrical, Garag...\n",
       "                                                             max_fun=15000,\n",
       "                                                             max_iter=200,\n",
       "                                                             momentum=0.9,\n",
       "                                                             n_iter_no_change=10,\n",
       "                                                             nesterovs_momentum=True,\n",
       "                                                             power_t=0.5,\n",
       "                                                             random_state=None,\n",
       "                                                             shuffle=True,\n",
       "                                                             solver='lbfgs',\n",
       "                                                             tol=0.0001,\n",
       "                                                             validation_fraction=0.1,\n",
       "                                                             verbose=False,\n",
       "                                                             warm_start=False))],\n",
       "                                   final_estimator=LinearRegression(copy_X=True,\n",
       "                                                                    fit_intercept=True,\n",
       "                                                                    n_jobs=None,\n",
       "                                                                    normalize=False),\n",
       "                                   n_jobs=None, passthrough=False,\n",
       "                                   verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_full.fit(data_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.11539236 0.14909517 0.13077614 0.11769475 0.13627109]\n",
      "Mean: 0.129845901828565\n",
      "Standard deviation: 0.012403532052781276\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(stack_reg, X_train, y_train,\n",
    "                         scoring=\"neg_mean_squared_log_error\", cv=5)\n",
    "stack_rmse_scores = np.sqrt(-scores)\n",
    "display_scores(stack_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pipeline_full.pkl']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(pipeline_full, \"pipeline_full.pkl\") \n",
    "# full_pipeline = joblib.load(\"pipeline_full.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = pd.DataFrame({'real': y_train, 'prediction': pipeline_full.predict(data_train)})\n",
    "# result[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline_full.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame({'Id': data_test['Id'], 'SalePrice': y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>118126.382120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>156355.173790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>182872.244635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>187063.922627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>196855.872305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>2915</td>\n",
       "      <td>82870.578678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>2916</td>\n",
       "      <td>83133.017257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>2917</td>\n",
       "      <td>158833.384770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>2918</td>\n",
       "      <td>113658.185682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>2919</td>\n",
       "      <td>216241.028845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1459 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id      SalePrice\n",
       "0     1461  118126.382120\n",
       "1     1462  156355.173790\n",
       "2     1463  182872.244635\n",
       "3     1464  187063.922627\n",
       "4     1465  196855.872305\n",
       "...    ...            ...\n",
       "1454  2915   82870.578678\n",
       "1455  2916   83133.017257\n",
       "1456  2917  158833.384770\n",
       "1457  2918  113658.185682\n",
       "1458  2919  216241.028845\n",
       "\n",
       "[1459 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "csv_path = os.path.join(cwd, 'kaggle-submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.to_csv(path_or_buf=csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# y_pred = stack_reg.predict(R_test)\n",
    "# stack_mse = mean_squared_error(u_test, y_pred)\n",
    "# stack_rmse = np.sqrt(stack_mse)\n",
    "# stack_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = pd.DataFrame({'real': u_test, 'stack': stack_reg.predict(R_test)})\n",
    "# result[:50]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
